name: Analytics CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  build-and-test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: user
          POSTGRES_PASSWORD: password
          POSTGRES_DB: ecom
        ports:
          - 5432:5432
        # Set health checks to wait until postgres is ready
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"

    - name: Install Dependencies
      run: |
        pip install -r requirements.txt

    - name: Run Data Loader (Mock Data for CI)
      env:
        POSTGRES_USER: user
        POSTGRES_PASSWORD: password
        POSTGRES_HOST: localhost
        POSTGRES_PORT: 5432
        POSTGRES_DB: ecom
      run: |
        # In CI, we likely don't have the big CSVs. 
        # load_data.py has a fallback to generate dummy data.
        python pipelines/extract_load/load_data.py

    - name: Run dbt Tests
      env:
        POSTGRES_USER: user
        POSTGRES_PASSWORD: password
        POSTGRES_HOST: localhost
        POSTGRES_PORT: 5432
        POSTGRES_DB: ecom
      run: |
        cd dbt
        dbt deps --profiles-dir .
        dbt build --profiles-dir .
    
    - name: Run Great Expectations
      env:
        POSTGRES_USER: user
        POSTGRES_PASSWORD: password
        POSTGRES_HOST: localhost
        POSTGRES_PORT: 5432
        POSTGRES_DB: ecom
      run: |
        python quality/run_ge_checks.py
